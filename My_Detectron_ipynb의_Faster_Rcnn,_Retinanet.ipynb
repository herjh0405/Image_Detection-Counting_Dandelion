{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucz3wqGjTV9x"
   },
   "source": [
    "# 2020 NIMS 산업수학 아카데미 민들레 튜토리얼 \n",
    "## 개화한 민들레 꽃의 갯수를 세는 프로그램 구축\n",
    "* 4~5월 한 달간의 민들레 꽃을 찍은 데이터를 제공받음 (dandelion_640.zip)\n",
    "* 데이터의 갯수가 너무 많으므로 꽃이 가장 많이 피어있는 4월 17일을 기준으로 앞으로 150장은 A팀이 뒤로 150장은 B팀이 라벨링 하기로 결정\n",
    "    * http://www.robots.ox.ac.uk/~vgg/software/via/via.html \n",
    "    * 이 사이트에서 라벨링을 진행하였고 bounding box를 기본적인 직사각형으로 하기로 결정\n",
    "    * 우리는 40, 40 35, 35을 나눠서 진행, B팀은 18, 19, 20, 21일을 36장씩 진행하기로 하였으나 20일 데이터에 이상이 있어 우리 데이터 75장과 18, 20일 데이터를 test셋 나머지를 triain셋으로 두고 작업을 진행\n",
    "* 여러가지 모델을 두고 작업하다가 Detectron2의 faster_rcnn, retinanet 두 가지 모델로 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8I2AbmwEKDZ3"
   },
   "source": [
    "# 데이터 처리 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RIx7G38hWRj"
   },
   "outputs": [],
   "source": [
    "!pip install pyyaml==5.1\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "assert torch.__version__.startswith(\"1.7\")\n",
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n",
    "!gcc --version\n",
    "\n",
    "exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTDsMRCpWlVB"
   },
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZuLruz4KIrV"
   },
   "source": [
    "## 데이터 불러오기 train set과 test set으로 구분 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTJ_o4gJabVH"
   },
   "outputs": [],
   "source": [
    "!unzip ./drive/\"My Drive\"/dandelion.zip > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vaWBa6UKRTP"
   },
   "source": [
    "* 이미지를 띄우기 위한 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JF6QZKqm7FT2"
   },
   "outputs": [],
   "source": [
    "from detectron2.structures import BoxMode\n",
    "\n",
    "def get_point_dicts(img_dir):\n",
    "    json_file = os.path.join(img_dir, \"via_region_data.json\") # json파일 읽어오기\n",
    "    with open(json_file) as f:\n",
    "        imgs_anns = json.load(f)\n",
    "\n",
    "    filename_list=[] #우리 json 파일은 dictionary안에 list가 있어 dictionary형태로 바꿔주는 작업\n",
    "    for idx, v in enumerate(imgs_anns.values()):\n",
    "        filename_list.append(v['filename']+str(v['size']))\n",
    "    for j in range(len(filename_list)):\n",
    "        imgs_anns[filename_list[j]]['regions']={str(i) : string for i , string in enumerate(imgs_anns[filename_list[j]]['regions'])}\n",
    "\n",
    "    dataset_dicts = []\n",
    "    for idx, v in enumerate(imgs_anns.values()):\n",
    "        record = {}\n",
    "\n",
    "        filename = os.path.join(img_dir, v[\"filename\"])\n",
    "        height, width = cv2.imread(filename).shape[:2]\n",
    "        \n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "\n",
    "        annos = v[\"regions\"]\n",
    "        \n",
    "        objs = [] # 왼쪽 상단이 (0,0)이라 (x,y)에서 (w,h)를 더한게 우측하단, 그렇게 bbox 구성\n",
    "        for _, anno in annos.items():\n",
    "            assert not anno[\"region_attributes\"]\n",
    "            anno=anno['shape_attributes']\n",
    "            px=float(anno['x'])\n",
    "            py=float(anno['y'])\n",
    "            pw=float(anno['width'])\n",
    "            ph=float(anno['height'])\n",
    "            poly=[(px+0.5*pw,py+0.5*ph)]\n",
    "            poly = [p for x in poly for p in x]\n",
    "\n",
    "            obj = {\n",
    "                \"bbox\": [px, py, px+pw, py+ph],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                # \"segmentation\": [poly],\n",
    "                \"category_id\": 0,\n",
    "            }\n",
    "            objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "\n",
    "for d in [\"train\", \"val\"]: # catalog에 등록\n",
    "    DatasetCatalog.register(\"dandelion_\"+d, lambda d=d: get_point_dicts(d))\n",
    "    MetadataCatalog.get(\"dandelion_\"+d).set(thing_classes=[\"dandelion\"])\n",
    "dandelion_metadata = MetadataCatalog.get(\"dandelion_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYcnuqlVKXZJ"
   },
   "source": [
    "* train set 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgoXL_nNYSRW"
   },
   "outputs": [],
   "source": [
    "dataset_dicts = get_point_dicts(\"train\")\n",
    "for d in random.sample(dataset_dicts, 1):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=dandelion_metadata, scale=0.5)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    cv2_imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UobEzUYvuwFJ"
   },
   "source": [
    "# 훈련 부분\n",
    "* faster_rcnn에서 R_101_FPN_3x가 50보다 좋은 성능을 보였기에 선택 \n",
    "    * LR=0.0025, Max_Iter=500, BATCH_SIZE=512를 저장해두겠음_01\n",
    "    * LR=0.0025, Max_Iter=500, BATCH_SIZE=128를 저장해두겠음_02\n",
    "        * BATCH_SIZE를 줄이는게 효과가 좋다고 판단\n",
    "    * LR=0.0025, Max_Iter=300, BATCH_SIZE=128를 저장해두겠음_03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NE8ROqRA28yZ"
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg() #config작업, parameter조정\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")) # detectron2/coc-detection에서 모델 불러오기(github)\n",
    "cfg.DATASETS.TRAIN = (\"dandelion_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 6 # 작업 대수\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 6\n",
    "cfg.SOLVER.BASE_LR = 0.0025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "\n",
    "cfg.OUTPUT_DIR='drive/My Drive/models/faster_rcnn_R_101_FPN_3x_03' # 이 곳에 학습 결과를 저장해둠, 할 때마다 계속 학습하지 않고 학습 데이터를 불러와서 사용하기 위해\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# retinanet 진행코드\n",
    "# from detectron2.engine import DefaultTrainer\n",
    "\n",
    "# cfg = get_cfg()\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"))\n",
    "# cfg.DATASETS.TRAIN = (\"dandelion_train\",)\n",
    "# cfg.DATASETS.TEST = ()\n",
    "# cfg.DATALOADER.NUM_WORKERS = 6\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "# cfg.SOLVER.IMS_PER_BATCH = 6\n",
    "# cfg.SOLVER.BASE_LR = 0.005  # pick a good LR\n",
    "# cfg.SOLVER.MAX_ITER = 500   # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "# cfg.MODEL.RETINANET.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "# cfg.MODEL.RETINANET.NUM_CLASSES = 1  # retinanet은 faster_rcnn과 달라서 model다음에 쓰는게 다름, 이런 거는 detectron2 retinanet number of classes로 들어가서 documents를 확인해보면 사용 방법을 알 수 있음\n",
    "\n",
    "# cfg.OUTPUT_DIR='drive/My Drive/models/retinanet_R_101_FPN_3x'\n",
    "# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# trainer = DefaultTrainer(cfg) \n",
    "# trainer.resume_or_load(resume=False)\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9EmDP4sOr_T"
   },
   "source": [
    "* 훈련 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlO3KuSuE-EK"
   },
   "outputs": [],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPNI5Jm-u74E"
   },
   "source": [
    "# 예측 모델 생성\n",
    "* 'drive/My Drive/models/faster_rcnn_R_101_FPN_3x' 여기 학습 결과가 저장되어 있기에 불러와서 예측 모델을 생성을 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJz59NSAE-W6"
   },
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"dandelion_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 20\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon)\n",
    "\n",
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.OUTPUT_DIR='drive/My Drive/models/faster_rcnn_R_101_FPN_3x_03'\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "# 이유\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# retinanet 진행코드\n",
    "# cfg = get_cfg()\n",
    "\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"))\n",
    "# cfg.DATASETS.TRAIN = (\"dandelion_train\",)\n",
    "# cfg.DATASETS.TEST = ()\n",
    "# cfg.DATALOADER.NUM_WORKERS = 20\n",
    "# cfg.MODEL.RETINANET.NUM_CLASSES = 1  # only has one class (ballon)\n",
    "\n",
    "# # Inference should use the config with parameters that are used in training\n",
    "# # cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "# cfg.OUTPUT_DIR='drive/My Drive/models/retinanet_R_101_FPN_3x_01'\n",
    "# cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "\n",
    "# cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.85   # set a custom testing threshold\n",
    "# predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ss6Q6ujfM6KJ"
   },
   "source": [
    "* Test dataset에 대해 잘 학습 되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49EV3ph9Ncj6"
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "dataset_dicts = get_point_dicts(\"val\")\n",
    "for d in random.sample(dataset_dicts, 5):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1], \n",
    "                   metadata=dandelion_metadata, \n",
    "                   scale=2, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to('cpu'))\n",
    "    cv2_imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0g1ahvzNsYv"
   },
   "source": [
    "* R2_score를 위해 리스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63MN4exuDdFZ"
   },
   "outputs": [],
   "source": [
    "real_ans=[]\n",
    "predict_ans=[]\n",
    "for d in dataset_dicts:\n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    real_ans.append(len(d['annotations']))\n",
    "    predict_ans.append(len(outputs['instances'].to('cpu').scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHdYfeEuS0Im"
   },
   "outputs": [],
   "source": [
    "# evaluation 작업\n",
    "# !rm -rf output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMJXirZ8OSq2"
   },
   "source": [
    "## Evaluation 검증\n",
    "* AP50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1RZ18tigSz8f"
   },
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "evaluator = COCOEvaluator(\"dandelion_val\", (\"bbox\",), False, output_dir=\"./output/\", )\n",
    "val_loader = build_detection_test_loader(cfg, \"dandelion_val\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKHJ1xnQOZPQ"
   },
   "source": [
    "* R2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwwTiCKhOKOK"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(real_ans, predict_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-FFjbiKOecA"
   },
   "source": [
    "* Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0EaqKI0VR_fH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# [i for i in range(len(real_ans))]\n",
    "re=pd.Series(real_ans)\n",
    "pre=pd.Series(predict_ans)\n",
    "err=pd.concat([re, pre], axis=1)\n",
    "err.columns=['실제','예측']\n",
    "err['오차']=err['실제']-err['예측']\n",
    "err\n",
    "\n",
    "sum(abs(err['오차'])), sum(err['실제'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VidUshucSXRp"
   },
   "outputs": [],
   "source": [
    "err"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "My_Detectron.ipynb의 Faster_Rcnn,  Retinanet",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
